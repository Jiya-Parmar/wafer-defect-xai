{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-XxbjETTjE9"
      },
      "outputs": [],
      "source": [
        "# =================================================================\n",
        "# 1.1. SETUP AND DEPENDENCIES\n",
        "# =================================================================\n",
        "print(\"Starting environment setup...\")\n",
        "!pip install -q kagglehub imbalanced-learn scikit-image\n",
        "!pip install -q opencv-python  # Required for image processing and visualization\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import cv2 # Used for image processing in visualization\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import kagglehub\n",
        "\n",
        "# Set Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 2.1. DATA ACQUISITION AND CLEANING\n",
        "# =================================================================\n",
        "print(\"\\nDownloading and processing WM-811K dataset...\")\n",
        "# Download data using kagglehub\n",
        "dataset_path = kagglehub.dataset_download(\"qingyi/wm811k-wafer-map\")\n",
        "pkl_file_path = os.path.join(dataset_path, \"LSWMD.pkl\")\n",
        "df = pd.read_pickle(pkl_file_path)\n",
        "\n",
        "# --- CRITICAL FIXES for Data Integrity ---\n",
        "# 1. Function to clean the nested array structure in 'failureType'\n",
        "def clean_failure_type(x):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return str(x[0]) if x.size > 0 else None\n",
        "    return str(x)\n",
        "df['failureType'] = df['failureType'].apply(clean_failure_type)\n",
        "\n",
        "# 2. Filter out 'none' class and NaN values to focus only on the 8 defect patterns\n",
        "df_defects = df[(df['failureType'] != \"['none']\") & (df['failureType'] != 'none')].copy()\n",
        "df_defects.dropna(subset=['failureType'], inplace=True)\n",
        "\n",
        "# Map labels and define global constants\n",
        "defect_types = df_defects['failureType'].unique()\n",
        "df_defects['label'] = df_defects['failureType'].map({label: i for i, label in enumerate(defect_types)})\n",
        "NUM_CLASSES = len(defect_types)\n",
        "\n",
        "print(f\"Final Defect Samples: {len(df_defects)}, Total Classes: {NUM_CLASSES}\")\n",
        "print(\"Initial Defect Class Distribution (Imbalanced):\\n\", df_defects['failureType'].value_counts())\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 2.2. DATA SPLIT AND IMBALANCE MITIGATION\n",
        "# =================================================================\n",
        "\n",
        "# 1. Split indices (Memory-efficient splitting)\n",
        "X_indices = df_defects.index.values\n",
        "X_train_indices, X_test_indices, y_train, y_test = train_test_split(\n",
        "    X_indices, df_defects['label'].values, test_size=0.2, stratify=df_defects['label'].values, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Random Oversampling on indices (to counter severe imbalance)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled_indices, y_train_resampled = ros.fit_resample(\n",
        "    X_train_indices.reshape(-1, 1), y_train\n",
        ")\n",
        "X_train_resampled_indices = X_train_resampled_indices.flatten()\n",
        "\n",
        "# 3. Calculate Class Weights (to maximize F1-score on minority classes)\n",
        "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "total_samples = class_counts.sum()\n",
        "class_weights_inverse = total_samples / (NUM_CLASSES * class_counts.values)\n",
        "class_weights_tensor = torch.tensor(class_weights_inverse, dtype=torch.float).to(device)\n",
        "\n",
        "print(\"\\nWeighted Loss Tensor Defined (Used in Training).\")\n",
        "\n",
        "# =================================================================\n",
        "# 2.3. CUSTOM PYTORCH DATASET (LAZY LOADING)\n",
        "# =================================================================\n",
        "\n",
        "def preprocess_wafer(wafer_map, target_size=(64, 64)):\n",
        "    \"\"\"Pre-processing function for on-the-fly loading.\"\"\"\n",
        "    wafer_map = wafer_map / 2.0\n",
        "    max_dim = max(wafer_map.shape)\n",
        "    squared_map = np.zeros((max_dim, max_dim))\n",
        "    h, w = wafer_map.shape\n",
        "    h_start = (max_dim - h) // 2\n",
        "    w_start = (max_dim - w) // 2\n",
        "    squared_map[h_start:h_start+h, w_start:w_start+w] = wafer_map\n",
        "    resized_map = resize(squared_map, target_size, anti_aliasing=True)\n",
        "    input_tensor = np.stack([resized_map] * 3, axis=0)\n",
        "    return torch.tensor(input_tensor.astype(np.float32))\n",
        "\n",
        "class WaferDataset(Dataset):\n",
        "    \"\"\"Loads and preprocesses data only when requested (Saves 10+ GB of RAM).\"\"\"\n",
        "    def __init__(self, df, indices, labels):\n",
        "        self.df = df\n",
        "        self.indices = indices\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    def __getitem__(self, idx):\n",
        "        df_idx = self.indices[idx]\n",
        "        wafer_map = self.df.loc[df_idx, 'waferMap']\n",
        "        image = preprocess_wafer(wafer_map)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "# Create the final memory-efficient Dataset instances\n",
        "train_dataset = WaferDataset(df_defects, X_train_resampled_indices, y_train_resampled)\n",
        "test_dataset = WaferDataset(df_defects, X_test_indices, y_test)\n",
        "\n",
        "print(\"\\nCustom PyTorch Datasets created for memory-efficient training.\")"
      ],
      "metadata": {
        "id": "vXWGvKWYTujW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 3.1. DEFINE CUSTOM CNN MODEL\n",
        "# =================================================================\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "class WaferCNN(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super(WaferCNN, self).__init__()\n",
        "        # Architecture: 6 Convolutional Layers for rich feature extraction\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1); self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1); self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1); self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1); self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1); self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1); self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x))))))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x))))))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.bn6(self.conv6(F.relu(self.bn5(self.conv5(x))))))\n",
        "        x = self.pool3(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "custom_model = WaferCNN(NUM_CLASSES).to(device)\n",
        "\n",
        "# Loss function uses the calculated inverse class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(custom_model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
        "NUM_EPOCHS = 15\n",
        "\n",
        "print(\"\\nStarting Custom CNN Training with Weighted Loss...\")\n",
        "# =================================================================\n",
        "# 3.2. TRAINING LOOP\n",
        "# =================================================================\n",
        "custom_model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = custom_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Training Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "print('\\nFinished Training! Model weights saved.')\n",
        "torch.save(custom_model.state_dict(), 'custom_wafer_cnn_weighted.pth')"
      ],
      "metadata": {
        "id": "1fQ2uMLdTwzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 4.1. MODEL EVALUATION\n",
        "# =================================================================\n",
        "print(\"\\n\\nEvaluating Final Model on Test Data...\")\n",
        "custom_model.eval()\n",
        "all_preds_custom = []\n",
        "all_labels_custom = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = custom_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds_custom.extend(predicted.cpu().numpy())\n",
        "        all_labels_custom.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy_custom = accuracy_score(all_labels_custom, all_preds_custom)\n",
        "f1_macro_custom = f1_score(all_labels_custom, all_preds_custom, average='macro')\n",
        "\n",
        "print(f\"\\n--- FINAL PERFORMANCE (Macro F1: {f1_macro_custom:.4f}) ---\")\n",
        "print(f\"Overall Accuracy: {accuracy_custom*100:.2f}%\")\n",
        "print(\"\\nFinal Classification Report:\\n\", classification_report(all_labels_custom, all_preds_custom, target_names=defect_types))\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 4.2. MANUAL GRAD-CAM VISUALIZATION\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"âœ… MANUAL GRAD-CAM: Generating Visual Proof...\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# Hooks to store the gradient and activation map\n",
        "gradients = None\n",
        "activations = None\n",
        "\n",
        "# 1. Hook Functions (Correct Signatures)\n",
        "def save_gradient(module, grad_input, grad_output):\n",
        "    global gradients\n",
        "    gradients = grad_output[0]\n",
        "\n",
        "def save_activations(module, input, output):\n",
        "    global activations\n",
        "    activations = output\n",
        "\n",
        "# Target the last convolutional layer (bn6)\n",
        "target_layer = custom_model.bn6\n",
        "\n",
        "# Register the hooks\n",
        "hook_handle_act = target_layer.register_forward_hook(save_activations)\n",
        "hook_handle_grad = target_layer.register_backward_hook(save_gradient)\n",
        "# ------------------------------------\n",
        "\n",
        "# Helper function to generate Grad-CAM\n",
        "def generate_grad_cam(input_tensor, predicted_class_idx):\n",
        "    input_tensor.requires_grad_(True)\n",
        "    output = custom_model(input_tensor)\n",
        "\n",
        "    custom_model.zero_grad()\n",
        "    one_hot = torch.zeros_like(output)\n",
        "    one_hot[0][predicted_class_idx] = 1\n",
        "    output.backward(gradient=one_hot, retain_graph=True)\n",
        "\n",
        "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "    # CRITICAL FIX: Explicitly move Tensors to CPU for multiplication\n",
        "    pooled_gradients_cpu = pooled_gradients.cpu()\n",
        "    activations_cpu = activations.detach().cpu()\n",
        "\n",
        "    for i in range(pooled_gradients_cpu.size(0)):\n",
        "        activations_cpu[:, i, :, :] *= pooled_gradients_cpu[i]\n",
        "\n",
        "    heatmap = torch.sum(activations_cpu, dim=1).squeeze()\n",
        "    heatmap = torch.relu(heatmap)\n",
        "\n",
        "    if torch.max(heatmap) > 0:\n",
        "        heatmap /= torch.max(heatmap)\n",
        "\n",
        "    np_heatmap = heatmap.cpu().numpy()\n",
        "    np_heatmap = cv2.resize(np_heatmap, (64, 64))\n",
        "\n",
        "    return np_heatmap\n",
        "\n",
        "# Helper function for visualization\n",
        "def visualize_cam(heatmap, rgb_img):\n",
        "    # Fix 1: Detach input tensor before converting to numpy\n",
        "    img_float = rgb_img.transpose(1, 2, 0)\n",
        "    img = (img_float * 255).astype(np.uint8)\n",
        "\n",
        "    # Fix 2: Ensure CV_8UC1 type for OpenCV colormapping\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_colored, 0.4, 0)\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return img, superimposed_img\n",
        "\n",
        "# --- Generate and Display Loop ---\n",
        "VISUALS_DIR = 'XAI_VISUALS'\n",
        "os.makedirs(VISUALS_DIR, exist_ok=True)\n",
        "sample_indices_to_view = [0, 50, 100]\n",
        "\n",
        "for i, test_idx in enumerate(sample_indices_to_view):\n",
        "    input_tensor, true_label_idx = test_dataset[test_idx]\n",
        "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_no_grad = custom_model(input_tensor)\n",
        "        predicted_class_idx = output_no_grad.argmax(dim=1).item()\n",
        "\n",
        "    # Generate Heatmap\n",
        "    np_heatmap = generate_grad_cam(input_tensor, predicted_class_idx)\n",
        "\n",
        "    # Prepare image for display\n",
        "    true_label = defect_types[true_label_idx.item()].strip(\"[]'\")\n",
        "    predicted_label = defect_types[predicted_class_idx].strip(\"[]'\")\n",
        "    rgb_img = input_tensor.squeeze(0).detach().cpu().numpy() # FINAL FIX: detach() is here\n",
        "\n",
        "    original_img, superimposed_img = visualize_cam(np_heatmap, rgb_img)\n",
        "\n",
        "    # Display and Save the results\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.suptitle(f'Sample {i+1} | True: {true_label} | Predicted: {predicted_label}', fontsize=14)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_img[:,:,0], cmap='gray')\n",
        "    plt.title(f'Wafer Map: {true_label}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(f'Grad-CAM: Model Focus on Defect')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"grad_cam_sample_{i+1}_{predicted_label}.png\"\n",
        "    save_path = os.path.join(VISUALS_DIR, filename)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Remove hooks after use (MANDATORY)\n",
        "hook_handle_act.remove()\n",
        "hook_handle_grad.remove()"
      ],
      "metadata": {
        "id": "r1adPfsmTzmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHvCAh14XQYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}